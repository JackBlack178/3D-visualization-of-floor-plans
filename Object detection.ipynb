{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object detection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1hGBOj_0uA2cMbgp917U6OPltrzSMkzmm","authorship_tag":"ABX9TyNomivIruvI9qb0AZYflAoK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"glIGbln9h3YU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hfI3obaddd7m","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":412},"executionInfo":{"status":"error","timestamp":1616168659221,"user_tz":-240,"elapsed":11836,"user":{"displayName":"Кирилл Сысоев","photoUrl":"","userId":"13232492055898604811"}},"outputId":"6eacb4ce-ca75-45f9-eb8d-c10f8b9103f5"},"source":["from __future__ import division\n","import os\n","import cv2\n","import numpy as np\n","import sys\n","import pickle\n","from optparse import OptionParser, OptionParser\n","import time\n","import sys\n","sys.path.append('/content/drive/MyDrive/Object-Detection-in-Floor-Plan-Images-master/frcnn-master/keras_frcnn/config.py')\n","from keras import backend as K\n","from keras.layers import Input\n","from keras.models import Model\n","sys.path.append('/content/drive/MyDrive/Object-Detection-in-Floor-Plan-Images-master/frcnn-master/keras_frcnn/roi_helpers.py')\n","import json, codecs\n","from google.colab import files\n","\n","\n","sys.setrecursionlimit(40000)\n","\n","parser = OptionParser()\n","\n","parser.add_option(\"-p\", \"--path\", dest=\"test_path\", help=\"Path to test data.\")\n","parser.add_option(\"-n\", \"--num_rois\", type=\"int\", dest=\"num_rois\",\n","\t\t\t\thelp=\"Number of ROIs per iteration. Higher means more memory use.\", default=32)\n","parser.add_option(\"--config_filename\", dest=\"config_filename\", help=\n","\t\t\t\t\"Location to read the metadata related to the training (generated when training).\",\n","\t\t\t\tdefault=\"config.pickle\")\n","parser.add_option(\"--network\", dest=\"network\", help=\"Base network to use. Supports vgg or resnet50.\", default='resnet50')\n","\n","#uploated = files.upload()\n","#ppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\n","(options, args) = parser.parse_args()\n","#options = optparse.Values()\n","#options =  OptionParser().add_option(test_path = '81.jpg')\n","#print(type(options))\n","#options =  OptionParser().add_option(num_rois= 32)\n","#options =  OptionParser().add_option(config_filename= 'config.pickle')\n","#options =  OptionParser().add_option(network= 'resnet50')\n","#args = []\n","\n","if not options.test_path:   # if filename is not given\n","  parser.error('Error: path to test data must be specified. Pass --path to command line')\n","\n","\n","config_output_filename = \"config.pickle\"\n","\n","with open(config_output_filename, 'rb') as f_in:\n","\tC = pickle.load(f_in)\n","\n","if C.network == 'resnet50':\n","\timport keras_frcnn.resnet as nn\n","elif C.network == 'vgg':\n","\timport keras_frcnn.vgg as nn\n","\n","# turn off any data augmentation at test time\n","C.use_horizontal_flips = False\n","C.use_vertical_flips = False\n","C.rot_90 = False\n","\n","img_path = \"81.jpg\"\n","\n","def format_img_size(img, C):\n","\t\"\"\" formats the image size based on config \"\"\"\n","\timg_min_side = float(C.im_size)\n","\t(height,width,_) = img.shape\n","\t\t\n","\tif width <= height:\n","\t\tratio = img_min_side/width\n","\t\tnew_height = int(ratio * height)\n","\t\tnew_width = int(img_min_side)\n","\telse:\n","\t\tratio = img_min_side/height\n","\t\tnew_width = int(ratio * width)\n","\t\tnew_height = int(img_min_side)\n","\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n","\treturn img, ratio\t\n","\n","def format_img_channels(img, C):\n","\t\"\"\" formats the image channels based on config \"\"\"\n","\timg = img[:, :, (2, 1, 0)]\n","\timg = img.astype(np.float32)\n","\timg[:, :, 0] -= C.img_channel_mean[0]\n","\timg[:, :, 1] -= C.img_channel_mean[1]\n","\timg[:, :, 2] -= C.img_channel_mean[2]\n","\timg /= C.img_scaling_factor\n","\timg = np.transpose(img, (2, 0, 1))\n","\timg = np.expand_dims(img, axis=0)\n","\treturn img\n","\n","def format_img(img, C):\n","\t\"\"\" formats an image for model prediction based on config \"\"\"\n","\timg, ratio = format_img_size(img, C)\n","\timg = format_img_channels(img, C)\n","\treturn img, ratio\n","\n","# Method to transform the coordinates of the bounding box to its original size\n","def get_real_coordinates(ratio, x1, y1, x2, y2):\n","\n","\treal_x1 = int(round(x1 // ratio))\n","\treal_y1 = int(round(y1 // ratio))\n","\treal_x2 = int(round(x2 // ratio))\n","\treal_y2 = int(round(y2 // ratio))\n","\n","\treturn (real_x1, real_y1, real_x2 ,real_y2)\n","\n","class_mapping = C.class_mapping\n","\n","if 'bg' not in class_mapping:\n","\tclass_mapping['bg'] = len(class_mapping)\n","\n","class_mapping = {v: k for k, v in class_mapping.items()}\n","print(class_mapping)\n","class_to_color = {class_mapping[v]: np.random.randint(0, 255, 3) for v in class_mapping}\n","C.num_rois = int(options.num_rois)\n","\n","if C.network == 'resnet50':\n","\tnum_features = 1024\n","elif C.network == 'vgg':\n","\tnum_features = 512\n","\n","if K.image_dim_ordering() == 'th':\n","\tinput_shape_img = (3, None, None)\n","\tinput_shape_features = (num_features, None, None)\n","else:\n","\tinput_shape_img = (None, None, 3)\n","\tinput_shape_features = (None, None, num_features)\n","\n","\n","img_input = Input(shape=input_shape_img)\n","roi_input = Input(shape=(C.num_rois, 4))\n","feature_map_input = Input(shape=input_shape_features)\n","\n","# define the base network (resnet here, can be VGG, Inception, etc)\n","shared_layers = nn.nn_base(img_input, trainable=True)\n","\n","# define the RPN, built on the base layers\n","num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n","rpn_layers = nn.rpn(shared_layers, num_anchors)\n","\n","classifier = nn.classifier(feature_map_input, roi_input, C.num_rois, nb_classes=len(class_mapping), trainable=True)\n","\n","model_rpn = Model(img_input, rpn_layers)\n","model_classifier_only = Model([feature_map_input, roi_input], classifier)\n","\n","model_classifier = Model([feature_map_input, roi_input], classifier)\n","\n","print('Loading weights from {}'.format(C.model_path))\n","model_rpn.load_weights(C.model_path, by_name=True)\n","model_classifier.load_weights(C.model_path, by_name=True)\n","\n","model_rpn.compile(optimizer='sgd', loss='mse')\n","model_classifier.compile(optimizer='sgd', loss='mse')\n","\n","all_imgs = []\n","\n","classes = {}\n","\n","bbox_threshold = 0.8\n","\n","visualise = True\n","\n","for idx, img_name in enumerate(sorted(os.listdir(img_path))):\n","\tif not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n","\t\tcontinue\n","\tprint(img_name)\n","\tst = time.time()\n","\tfilepath = os.path.join(img_path,img_name)\n","\n","\timg = cv2.imread(filepath)\n","\n","\tX, ratio = format_img(img, C)\n","\n","\tif K.image_dim_ordering() == 'tf':\n","\t\tX = np.transpose(X, (0, 2, 3, 1))\n","\n","\t# get the feature maps and output from the RPN\n","\t[Y1, Y2, F] = model_rpn.predict(X)\n","\t\n","\n","\tR = roi_helpers.rpn_to_roi(Y1, Y2, C, K.image_dim_ordering(), overlap_thresh=0.7)\n","\n","\t# convert from (x1,y1,x2,y2) to (x,y,w,h)\n","\tR[:, 2] -= R[:, 0]\n","\tR[:, 3] -= R[:, 1]\n","\n","\t# apply the spatial pyramid pooling to the proposed regions\n","\tbboxes = {}\n","\tprobs = {}\n","\n","\tfor jk in range(R.shape[0]//C.num_rois + 1):\n","\t\tROIs = np.expand_dims(R[C.num_rois*jk:C.num_rois*(jk+1), :], axis=0)\n","\t\tif ROIs.shape[1] == 0:\n","\t\t\tbreak\n","\n","\t\tif jk == R.shape[0]//C.num_rois:\n","\t\t\t#pad R\n","\t\t\tcurr_shape = ROIs.shape\n","\t\t\ttarget_shape = (curr_shape[0],C.num_rois,curr_shape[2])\n","\t\t\tROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n","\t\t\tROIs_padded[:, :curr_shape[1], :] = ROIs\n","\t\t\tROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n","\t\t\tROIs = ROIs_padded\n","\n","\t\t[P_cls, P_regr] = model_classifier_only.predict([F, ROIs])\n","\n","\t\tfor ii in range(P_cls.shape[1]):\n","\n","\t\t\tif np.max(P_cls[0, ii, :]) < bbox_threshold or np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n","\t\t\t\tcontinue\n","\n","\t\t\tcls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n","\n","\t\t\tif cls_name not in bboxes:\n","\t\t\t\tbboxes[cls_name] = []\n","\t\t\t\tprobs[cls_name] = []\n","\n","\t\t\t(x, y, w, h) = ROIs[0, ii, :]\n","\n","\t\t\tcls_num = np.argmax(P_cls[0, ii, :])\n","\t\t\ttry:\n","\t\t\t\t(tx, ty, tw, th) = P_regr[0, ii, 4*cls_num:4*(cls_num+1)]\n","\t\t\t\ttx /= C.classifier_regr_std[0]\n","\t\t\t\tty /= C.classifier_regr_std[1]\n","\t\t\t\ttw /= C.classifier_regr_std[2]\n","\t\t\t\tth /= C.classifier_regr_std[3]\n","\t\t\t\tx, y, w, h = roi_helpers.apply_regr(x, y, w, h, tx, ty, tw, th)\n","\t\t\texcept:\n","\t\t\t\tpass\n","\t\t\tbboxes[cls_name].append([C.rpn_stride*x, C.rpn_stride*y, C.rpn_stride*(x+w), C.rpn_stride*(y+h)])\n","\t\t\tprobs[cls_name].append(np.max(P_cls[0, ii, :]))\n","\n","\tall_dets = []\n","\tall_objs = []\n","\tfor key in bboxes:\n","\t\tbbox = np.array(bboxes[key])\n","\t\tnew_boxes, new_probs = roi_helpers.non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.5)\n","\t\t#print(key)\n","\t\t#print(bboxes[key])\n","\t\t#print(probs[key])\n","\t\t#print(new_boxes)\n","\t\t#print(new_probs)\n","\t\t#for dwn in range(len(bboxes[key])):\n","\t\t\t#all_objs.append((key,bboxes[key][dwn],100*new_probs[dwn]))\n","\t\t\n","\t\t\n","\t\tfor jk in range(new_boxes.shape[0]):\n","\t\t\t(x1, y1, x2, y2) = new_boxes[jk,:]\n","\n","\t\t\t(real_x1, real_y1, real_x2, real_y2) = get_real_coordinates(ratio, x1, y1, x2, y2)\n","\t\t\t#print(real_x1, real_y1)\n","\t\t\tcv2.rectangle(img,(real_x1, real_y1), (real_x2, real_y2), (int(class_to_color[key][0]), int(class_to_color[key][1]), int(class_to_color[key][2])),2)\n","\n","\t\t\ttextLabel = '{}: {}'.format(key,int(100*new_probs[jk]))\n","\t\t\n","\t\t\t\n","\t\t\tall_dets.append((key, 100*new_probs[jk]))\n","\t\t\tall_objs.append((key,[real_x1, real_y1, real_x2, real_y2],100*new_probs[jk]))\t\n","\t\t\t\n","\t\t\t(retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,1,1)\n","\t\t\ttextOrg = (real_x1, real_y1-0)\n","\n","\t\t\tcv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 15)\n","\t\t\tcv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), 15)\n","\t\t\tcol = np.random.rand(3)*255\n","\t\t\tcv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 3, (col), 4)\n","\n","\tprint('Elapsed time = {}'.format(time.time() - st))\n","\t#print(all_dets)\n","\tprint(all_objs)\n","\tjson_list = []\n","\tres_dic = {}\n","\tfor reg in all_objs:\n","\t\tres_dic['label'] = reg[0]\n","\t\tres_dic['confidence'] = reg[2]/100\n","\t\tres_dic['topleft'] = {'x':reg[1][0],'y':reg[1][1]}\n","\t\tres_dic['bottomright'] = {'x':reg[1][2],'y':reg[1][3]}\n","\t\tjson_list.append(res_dic)\n","\t\tres_dic = {}\n","\n","\tprint(json_list)\n","\tfname = img_name.split('.')[0]\n","\t\n","\twith open('./output/{}.json'.format(fname),'w') as outfile:\n","\t\tjson.dump(json_list,codecs.getwriter('utf-8')(outfile),ensure_ascii=False)\n","\t\n","\t#scale_percent = 20\n","\t#width = int(img.shape[1] * scale_percent / 100)\n","\t#height = int(img.shape[0] * scale_percent / 100)\n","\t#dim = (width, height)\n","\t#img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n","\t\t\n","\t#cv2.imshow('img', img)\n","\t#cv2.waitKey(0)\n","\tcv2.imwrite('./results_imgs/{}.png'.format(img_name.split('.')[0]),img)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["123\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-8dffd871-f919-4479-92c5-8c0443d1b8b8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8dffd871-f919-4479-92c5-8c0443d1b8b8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3e65abb7ef58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--network\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"network\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Base network to use. Supports vgg or resnet50.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0muploated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;31m#ppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"d99NyGbuMA-3","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"ok","timestamp":1616171980850,"user_tz":-240,"elapsed":4495,"user":{"displayName":"Кирилл Сысоев","photoUrl":"","userId":"13232492055898604811"}},"outputId":"2d077dd0-9f13-4aec-84a9-64cc33c2ad82"},"source":["import os  \n","import sys\n","os.system('python /content/drive/MyDrive/Object-Detection-in-Floor-Plan-Images-master/frcnn-master/only_print.py')\n","sys.path.append('/content/drive/MyDrive/Object-Detection-in-Floor-Plan-Images-master/frcnn-master/config.pickle')\n","\n","from subprocess import Popen\n","#my_file = open('/content/drive/MyDrive/Object-Detection-in-Floor-Plan-Images-master/frcnn-master/only_print.py')\n","%run '/content/drive/MyDrive/Object-Detection-in-Floor-Plan-Images-master/frcnn-master/object_detection.py' '-p 81.jpg'\n","#Popen('python /content/drive/MyDrive/Object-Detection-in-Floor-Plan-Images-master/frcnn-master/only_print.py')"],"execution_count":1,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/content/drive/MyDrive/Object-Detection-in-Floor-Plan-Images-master/frcnn-master/object_detection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_output_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: bad magic number in 'keras_frcnn': b'\\x03\\xf3\\r\\n'"]}]}]}